services:
  zookeeper:
    image: confluentinc/cp-zookeeper:7.3.0
    hostname: zookeeper
    container_name: zookeeper
    ports:
      - "2181:2181"
    networks: 
      - kafka_network
    env_file: server.env

  broker:
    image: confluentinc/cp-kafka:7.3.0
    hostname: broker
    container_name: broker
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
    networks: 
      - kafka_network
    env_file: server.env
    environment:
      KAFKA_NUM_PARTITIONS: ${DEFAULT_NUMBER_OF_PARTITIONS}

  kafka-connect:
    image: stream-connector:${VERSION}
    build:
      context: src/stream-connector
    hostname: kafka-connect
    container_name: kafka-connect
    volumes:
      - ${PWD}/data/input:/data/input
      - ${PWD}/data/error:/data/error
      - ${PWD}/data/processed:/data/processed
    depends_on:
      - broker
    networks:
      - kafka_network
    ports:
      - "8083:8083"
    env_file: server.env
    environment:
      CONNECT_FILES_ENABLE: ${CONNECT_FILES_ENABLE}
      TWITTER_API_ENABLE: ${TWITTER_API_ENABLE}
      ELASTICSEARCH_ENABLE: ${ELASTICSEARCH_ENABLE}

  schema-registry:
    image: confluentinc/cp-schema-registry:7.3.0
    hostname: schema-registry
    container_name: schema-registry
    depends_on:
      - broker
    ports:
      - "8081:8081"
    networks:
      - kafka_network
    env_file: server.env

  predictor:
    image: predictor:${VERSION}
    depends_on:
      - broker
    build:
      context: ./src
      dockerfile: ./predictor/Dockerfile
    deploy:
      mode: replicated
      replicas: ${PREDICTOR_N_REPLICAS}
    networks: 
      - kafka_network
    environment:
      CONFIG_PATHS: ./predictor/configuration.yaml

  twitter-api:
    image: twitter-api:${VERSION}
    build:
      context: ./src
      dockerfile: ./tw-api/Dockerfile
    hostname: twitter-api
    container_name: twitter-api
    networks: 
      - kafka_network
    volumes:
      - ${PWD}/data/api:/data
    ports:
      - "8099:8099"
    environment:
      TWEETS_FILE_PATH: /data/tweets_processed.csv

  twitter-api-processer:
    image: twitter-api-processer:${VERSION}
    hostname: twitter-api-processer
    # container_name: twitter-api-processer
    build:
      context: ./src
      dockerfile: ./tw-api-processer/Dockerfile
    networks: 
      - kafka_network
    deploy:
      mode: replicated
      replicas: ${PROCESSER_N_REPLICAS}
    environment:
      CONFIG_PATHS: ./tw-api-processer/configuration.yaml

  ksqldb-server:
    image: confluentinc/ksqldb-server:0.28.2
    container_name: ksqldb
    depends_on:
      - broker
    ports:
      - "8088:8088"
    networks: 
      - kafka_network
    env_file: server.env

  ksqldb-cli:
    image: confluentinc/ksqldb-cli:0.28.2
    container_name: ksqldb-cli
    depends_on:
      - broker
      - ksqldb-server
    networks: 
      - kafka_network
    entrypoint: /bin/sh
    tty: true

  elasticsearch:
    image: elasticsearch:7.17.10
    hostname: elasticsearch
    container_name: elasticsearch
    ports:
      - "9200:9200"
      - "9300:9300"
    networks: 
      - kafka_network
    volumes:
      - elastic-data:/usr/share/elasticsearch/data
    environment:
      - "discovery.type=single-node"
      - "xpack.security.enabled=false"
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"

  kibana:
    image: kibana:7.17.10
    hostname: kibana
    container_name: kibana
    ports:
      - "5601:5601"
    networks: 
      - kafka_network
    environment:
      ELASTICSEARCH_HOSTS: '["http://elasticsearch:9200"]'

  kafka-ui:
    container_name: kafka-ui
    image: provectuslabs/kafka-ui:latest
    ports:
      - 8080:8080
    networks: 
      - kafka_network
    environment:
      DYNAMIC_CONFIG_ENABLED: true
    volumes:
      - ${PWD}/kafka-ui-config.yaml:/etc/kafkaui/dynamic_config.yaml

networks:
  kafka_network:

volumes:
  elastic-data: